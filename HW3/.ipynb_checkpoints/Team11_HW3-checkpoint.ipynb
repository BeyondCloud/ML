{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "reset_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# load data: digits 5 to 9, but still label with 0 to 4, \n",
    "# because TensorFlow expects label's integers from 0 to n_classes-1.\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\")\n",
    "\n",
    "X_train2_full = mnist.train.images[mnist.train.labels >= 5]\n",
    "y_train2_full = mnist.train.labels[mnist.train.labels >= 5] - 5\n",
    "X_valid2_full = mnist.validation.images[mnist.validation.labels >= 5]\n",
    "y_valid2_full = mnist.validation.labels[mnist.validation.labels >= 5] - 5\n",
    "X_test2 = mnist.test.images[mnist.test.labels >= 5]\n",
    "y_test2 = mnist.test.labels[mnist.test.labels >= 5] - 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we want to keep only 100 instances per class in the training set \n",
    "# and let's keep only 30 instances per class in the validation set\n",
    "# tesing set is already loaded above\n",
    "def sample_n_instances_per_class(X, y, n=100):\n",
    "    Xs, ys = [], []\n",
    "    for label in np.unique(y):\n",
    "        idx = (y == label)\n",
    "        Xc = X[idx][:n]\n",
    "        yc = y[idx][:n]\n",
    "        Xs.append(Xc)\n",
    "        ys.append(yc)\n",
    "    return np.concatenate(Xs), np.concatenate(ys)\n",
    "\n",
    "X_train2, y_train2 = sample_n_instances_per_class(X_train2_full, y_train2_full, n=100)\n",
    "X_valid2, y_valid2 = sample_n_instances_per_class(X_valid2_full, y_valid2_full, n=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#restore HW2 model's tensor by name\n",
    "\n",
    "tf.reset_default_graph()\n",
    "restore_saver = tf.train.import_meta_graph( \"./model/Team11_HW2.ckpt.meta\")\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "loss = tf.get_default_graph().get_tensor_by_name(\"loss:0\")\n",
    "Y_proba = tf.get_default_graph().get_tensor_by_name(\"Y_proba:0\")\n",
    "logits = Y_proba.op.inputs[0]\n",
    "accuracy = tf.get_default_graph().get_tensor_by_name(\"accuracy:0\")\n",
    "\n",
    "#get the softmax layer\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"logits\")\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "\n",
    "#exclude other trainable variable except softmax layer\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "five_frozen_saver = tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW3.1 train softmax only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/Team11_HW2.ckpt\n",
      "0\tValid loss: 1.2603\tBest loss: 1.2603\tACC: 0.50\n",
      "1\tValid loss: 1.2864\tBest loss: 1.2603\tACC: 0.49\n",
      "2\tValid loss: 1.2394\tBest loss: 1.2394\tACC: 0.51\n",
      "3\tValid loss: 1.2301\tBest loss: 1.2301\tACC: 0.51\n",
      "4\tValid loss: 1.1631\tBest loss: 1.1631\tACC: 0.55\n",
      "5\tValid loss: 1.2169\tBest loss: 1.1631\tACC: 0.46\n",
      "6\tValid loss: 1.2673\tBest loss: 1.1631\tACC: 0.52\n",
      "7\tValid loss: 1.0506\tBest loss: 1.0506\tACC: 0.55\n",
      "8\tValid loss: 1.1567\tBest loss: 1.0506\tACC: 0.48\n",
      "9\tValid loss: 1.1438\tBest loss: 1.0506\tACC: 0.53\n",
      "10\tValid loss: 1.0230\tBest loss: 1.0230\tACC: 0.61\n",
      "11\tValid loss: 1.0987\tBest loss: 1.0230\tACC: 0.55\n",
      "12\tValid loss: 1.1874\tBest loss: 1.0230\tACC: 0.49\n",
      "13\tValid loss: 1.2647\tBest loss: 1.0230\tACC: 0.45\n",
      "14\tValid loss: 1.2307\tBest loss: 1.0230\tACC: 0.54\n",
      "15\tValid loss: 1.1329\tBest loss: 1.0230\tACC: 0.59\n",
      "16\tValid loss: 1.1388\tBest loss: 1.0230\tACC: 0.56\n",
      "17\tValid loss: 1.1173\tBest loss: 1.0230\tACC: 0.56\n",
      "18\tValid loss: 1.2515\tBest loss: 1.0230\tACC: 0.47\n",
      "19\tValid loss: 1.1061\tBest loss: 1.0230\tACC: 0.55\n",
      "20\tValid loss: 1.1012\tBest loss: 1.0230\tACC: 0.64\n",
      "21\tValid loss: 1.1790\tBest loss: 1.0230\tACC: 0.54\n",
      "22\tValid loss: 1.0404\tBest loss: 1.0230\tACC: 0.62\n",
      "23\tValid loss: 1.1184\tBest loss: 1.0230\tACC: 0.54\n",
      "24\tValid loss: 1.0313\tBest loss: 1.0230\tACC: 0.59\n",
      "25\tValid loss: 1.1451\tBest loss: 1.0230\tACC: 0.51\n",
      "26\tValid loss: 1.1976\tBest loss: 1.0230\tACC: 0.46\n",
      "27\tValid loss: 1.1695\tBest loss: 1.0230\tACC: 0.49\n",
      "28\tValid loss: 1.1586\tBest loss: 1.0230\tACC: 0.53\n",
      "29\tValid loss: 1.1162\tBest loss: 1.0230\tACC: 0.60\n",
      "30\tValid loss: 1.1959\tBest loss: 1.0230\tACC: 0.48\n",
      "Early stop triggered\n",
      "Training time: 4.2sec\n",
      "INFO:tensorflow:Restoring parameters from ./Team11_HW3_1.ckpt\n",
      "test acc: 0.4902\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "n_epochs = 1000\n",
    "#early stop if no progress in 20 epochs\n",
    "early_stop_trigger_step = 20\n",
    "early_stop_cnt = 0\n",
    "batch_size = 30\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./model/Team11_HW2.ckpt\")\n",
    "    \n",
    "    #initialize softmax layer\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "    \n",
    "    best_loss = np.infty\n",
    "    \n",
    "    #create timer for benchmark\n",
    "    t0 = time.time()\n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        #random select training data\n",
    "        rnd_idx = np.random.permutation(len(X_train2)) #create 1~500 rnd\n",
    "        for rnd_idxs in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_idxs], y_train2[rnd_idxs]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "            \n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        \n",
    "        if loss_val < best_loss:\n",
    "            early_stop_cnt = 0\n",
    "            best_loss = loss_val\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "            if early_stop_cnt > early_stop_trigger_step:\n",
    "                save_path = five_frozen_saver.save(sess, \"./Team11_HW3_1.ckpt\")\n",
    "                print(\"Early stop triggered\")\n",
    "                break\n",
    "        print(\"{}\\tValid loss: {:.4f}\\tBest loss: {:.4f}\\tACC: {:.2f}\".format(\n",
    "            epoch, loss_val, best_loss, acc_val ))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Training time: {:.1f}sec\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team11_HW3_1.ckpt\")\n",
    "    acc_test = sess.run(accuracy,feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test acc: {:.4f}\".format(acc_test ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW3.2 cache 5th layer's output\n",
    "We found that training time speed up almost 2x if cache method is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/Team11_HW2.ckpt\n",
      "0\tValid loss: 1.2686\tBest loss: 1.2686\tACC: 0.51\n",
      "1\tValid loss: 1.1892\tBest loss: 1.1892\tACC: 0.51\n",
      "2\tValid loss: 1.1515\tBest loss: 1.1515\tACC: 0.55\n",
      "3\tValid loss: 1.2110\tBest loss: 1.1515\tACC: 0.51\n",
      "4\tValid loss: 1.1369\tBest loss: 1.1369\tACC: 0.52\n",
      "5\tValid loss: 1.1092\tBest loss: 1.1092\tACC: 0.53\n",
      "6\tValid loss: 1.1373\tBest loss: 1.1092\tACC: 0.56\n",
      "7\tValid loss: 1.1340\tBest loss: 1.1092\tACC: 0.54\n",
      "8\tValid loss: 1.1098\tBest loss: 1.1092\tACC: 0.57\n",
      "9\tValid loss: 1.1918\tBest loss: 1.1092\tACC: 0.49\n",
      "10\tValid loss: 1.1162\tBest loss: 1.1092\tACC: 0.54\n",
      "11\tValid loss: 1.1755\tBest loss: 1.1092\tACC: 0.51\n",
      "12\tValid loss: 1.2031\tBest loss: 1.1092\tACC: 0.51\n",
      "13\tValid loss: 1.1190\tBest loss: 1.1092\tACC: 0.53\n",
      "14\tValid loss: 1.1454\tBest loss: 1.1092\tACC: 0.51\n",
      "15\tValid loss: 1.1927\tBest loss: 1.1092\tACC: 0.53\n",
      "16\tValid loss: 1.1284\tBest loss: 1.1092\tACC: 0.54\n",
      "17\tValid loss: 1.2051\tBest loss: 1.1092\tACC: 0.50\n",
      "18\tValid loss: 1.1251\tBest loss: 1.1092\tACC: 0.53\n",
      "19\tValid loss: 1.2389\tBest loss: 1.1092\tACC: 0.48\n",
      "20\tValid loss: 1.1383\tBest loss: 1.1092\tACC: 0.55\n",
      "21\tValid loss: 1.1336\tBest loss: 1.1092\tACC: 0.55\n",
      "22\tValid loss: 1.2120\tBest loss: 1.1092\tACC: 0.51\n",
      "23\tValid loss: 1.1299\tBest loss: 1.1092\tACC: 0.55\n",
      "24\tValid loss: 1.1318\tBest loss: 1.1092\tACC: 0.51\n",
      "25\tValid loss: 1.2255\tBest loss: 1.1092\tACC: 0.50\n",
      "Early stop triggered\n",
      "Training time: 2.0sec\n",
      "INFO:tensorflow:Restoring parameters from ./Team11_HW3_2.ckpt\n",
      "test acc: 0.4801\n"
     ]
    }
   ],
   "source": [
    "   \n",
    "n_epochs = 1000\n",
    "#early stop if no progress in 20 epochs\n",
    "early_stop_trigger_step = 20\n",
    "early_stop_cnt = 0\n",
    "batch_size = 30\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./model/Team11_HW2.ckpt\")\n",
    "    for var in output_layer_vars:\n",
    "        var.initializer.run()\n",
    "\n",
    "    #cache 5th layer before training\n",
    "    hidden5_out = tf.get_default_graph().get_tensor_by_name(\"hidden5_out:0\")\n",
    "    h5_train_cache = sess.run(hidden5_out,feed_dict={X: X_train2, y: y_train2})\n",
    "    h5_valid_cache = sess.run(hidden5_out,feed_dict={X: X_valid2, y: y_valid2})\n",
    "    \n",
    "    best_loss = np.infty\n",
    "    \n",
    "    #create timer for benchmark\n",
    "    t0 = time.time()\n",
    "    #start training and print each epoch\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2)) \n",
    "        #get 5th layer from HW2 and feed as input of softmax layer\n",
    "        for rnd_idxs in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            h5_batch, y_batch = h5_train_cache[rnd_idxs], y_train2[rnd_idxs]\n",
    "            sess.run(training_op, feed_dict={hidden5_out: h5_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={hidden5_out: h5_valid_cache, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "            if early_stop_cnt > early_stop_trigger_step:\n",
    "                save_path = five_frozen_saver.save(sess, \"./Team11_HW3_2.ckpt\")\n",
    "                print(\"Early stop triggered\")\n",
    "                break\n",
    "        print(\"{}\\tValid loss: {:.4f}\\tBest loss: {:.4f}\\tACC: {:.2f}\".format(\n",
    "            epoch, loss_val, best_loss, acc_val))\n",
    "\n",
    "    t1 = time.time()\n",
    "    print(\"Training time: {:.1f}sec\".format(t1 - t0))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    five_frozen_saver.restore(sess, \"./Team11_HW3_2.ckpt\")\n",
    "    acc_test = sess.run(accuracy,feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test acc: {:.4f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW3.3 Load HW2 model again, now use 4th hidden layer's output and feed them into new softmax layer:\n",
    "Result better than 3_1 and 3_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "\n",
    "n_outputs = 5\n",
    "#get tensor from HW2\n",
    "restore_saver = tf.train.import_meta_graph(\"./model/Team11_HW2.ckpt.meta\")\n",
    "he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "X = tf.get_default_graph().get_tensor_by_name(\"X:0\")\n",
    "y = tf.get_default_graph().get_tensor_by_name(\"y:0\")\n",
    "\n",
    "#get 4th hidden layer before training\n",
    "#here we connect 4th hidden layer output to new softmax layer\n",
    "hidden4_out = tf.get_default_graph().get_tensor_by_name(\"hidden4_out:0\")\n",
    "logits = tf.layers.dense(hidden4_out, n_outputs, kernel_initializer=he_init, name=\"new_logits\")\n",
    "Y_proba = tf.nn.softmax(logits)\n",
    "xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=logits)\n",
    "\n",
    "#exclude other trainable value and keep only softmax layer trainable\n",
    "#define optimizer and loss function\n",
    "loss = tf.reduce_mean(xentropy, name=\"loss\")\n",
    "correct = tf.nn.in_top_k(logits, y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "output_layer_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"new_logits\")\n",
    "learning_rate = 0.01\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam2\")\n",
    "training_op = optimizer.minimize(loss, var_list=output_layer_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "four_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model/Team11_HW2.ckpt\n",
      "0\tValid loss: 2.9443\tBest loss: 2.9443\tACC: 0.55\n",
      "1\tValid loss: 2.0043\tBest loss: 2.0043\tACC: 0.46\n",
      "2\tValid loss: 2.2452\tBest loss: 2.0043\tACC: 0.47\n",
      "3\tValid loss: 1.9935\tBest loss: 1.9935\tACC: 0.53\n",
      "4\tValid loss: 1.7248\tBest loss: 1.7248\tACC: 0.53\n",
      "5\tValid loss: 2.1877\tBest loss: 1.7248\tACC: 0.47\n",
      "6\tValid loss: 2.6916\tBest loss: 1.7248\tACC: 0.50\n",
      "7\tValid loss: 2.5146\tBest loss: 1.7248\tACC: 0.47\n",
      "8\tValid loss: 1.6377\tBest loss: 1.6377\tACC: 0.53\n",
      "9\tValid loss: 1.9110\tBest loss: 1.6377\tACC: 0.52\n",
      "10\tValid loss: 1.7411\tBest loss: 1.6377\tACC: 0.49\n",
      "11\tValid loss: 2.0451\tBest loss: 1.6377\tACC: 0.46\n",
      "12\tValid loss: 2.0910\tBest loss: 1.6377\tACC: 0.38\n",
      "13\tValid loss: 2.0179\tBest loss: 1.6377\tACC: 0.45\n",
      "14\tValid loss: 1.7109\tBest loss: 1.6377\tACC: 0.47\n",
      "15\tValid loss: 2.0010\tBest loss: 1.6377\tACC: 0.55\n",
      "16\tValid loss: 1.7463\tBest loss: 1.6377\tACC: 0.47\n",
      "17\tValid loss: 1.5427\tBest loss: 1.5427\tACC: 0.47\n",
      "18\tValid loss: 2.0850\tBest loss: 1.5427\tACC: 0.41\n",
      "19\tValid loss: 2.2454\tBest loss: 1.5427\tACC: 0.45\n",
      "20\tValid loss: 1.5721\tBest loss: 1.5427\tACC: 0.52\n",
      "21\tValid loss: 1.7070\tBest loss: 1.5427\tACC: 0.49\n",
      "22\tValid loss: 1.7778\tBest loss: 1.5427\tACC: 0.46\n",
      "23\tValid loss: 2.0025\tBest loss: 1.5427\tACC: 0.47\n",
      "24\tValid loss: 1.7782\tBest loss: 1.5427\tACC: 0.51\n",
      "25\tValid loss: 1.6480\tBest loss: 1.5427\tACC: 0.51\n",
      "26\tValid loss: 1.8004\tBest loss: 1.5427\tACC: 0.50\n",
      "27\tValid loss: 1.7827\tBest loss: 1.5427\tACC: 0.48\n",
      "28\tValid loss: 1.4642\tBest loss: 1.4642\tACC: 0.53\n",
      "29\tValid loss: 1.5386\tBest loss: 1.4642\tACC: 0.51\n",
      "30\tValid loss: 1.6889\tBest loss: 1.4642\tACC: 0.45\n",
      "31\tValid loss: 1.5985\tBest loss: 1.4642\tACC: 0.53\n",
      "32\tValid loss: 1.8549\tBest loss: 1.4642\tACC: 0.48\n",
      "33\tValid loss: 1.4617\tBest loss: 1.4617\tACC: 0.51\n",
      "34\tValid loss: 1.6499\tBest loss: 1.4617\tACC: 0.50\n",
      "35\tValid loss: 1.7942\tBest loss: 1.4617\tACC: 0.51\n",
      "36\tValid loss: 1.7603\tBest loss: 1.4617\tACC: 0.47\n",
      "37\tValid loss: 1.7351\tBest loss: 1.4617\tACC: 0.49\n",
      "38\tValid loss: 1.7455\tBest loss: 1.4617\tACC: 0.37\n",
      "39\tValid loss: 2.1393\tBest loss: 1.4617\tACC: 0.49\n",
      "40\tValid loss: 1.6166\tBest loss: 1.4617\tACC: 0.51\n",
      "41\tValid loss: 1.5586\tBest loss: 1.4617\tACC: 0.48\n",
      "42\tValid loss: 1.6612\tBest loss: 1.4617\tACC: 0.58\n",
      "43\tValid loss: 2.0085\tBest loss: 1.4617\tACC: 0.39\n",
      "44\tValid loss: 1.5411\tBest loss: 1.4617\tACC: 0.47\n",
      "45\tValid loss: 1.8246\tBest loss: 1.4617\tACC: 0.42\n",
      "46\tValid loss: 1.4883\tBest loss: 1.4617\tACC: 0.58\n",
      "47\tValid loss: 1.6456\tBest loss: 1.4617\tACC: 0.53\n",
      "48\tValid loss: 1.6062\tBest loss: 1.4617\tACC: 0.52\n",
      "49\tValid loss: 1.7475\tBest loss: 1.4617\tACC: 0.53\n",
      "50\tValid loss: 1.5761\tBest loss: 1.4617\tACC: 0.51\n",
      "51\tValid loss: 1.3024\tBest loss: 1.3024\tACC: 0.58\n",
      "52\tValid loss: 1.6577\tBest loss: 1.3024\tACC: 0.49\n",
      "53\tValid loss: 1.4017\tBest loss: 1.3024\tACC: 0.55\n",
      "54\tValid loss: 2.0147\tBest loss: 1.3024\tACC: 0.46\n",
      "55\tValid loss: 1.6391\tBest loss: 1.3024\tACC: 0.49\n",
      "56\tValid loss: 1.6014\tBest loss: 1.3024\tACC: 0.56\n",
      "57\tValid loss: 1.5449\tBest loss: 1.3024\tACC: 0.58\n",
      "58\tValid loss: 1.5427\tBest loss: 1.3024\tACC: 0.52\n",
      "59\tValid loss: 1.5142\tBest loss: 1.3024\tACC: 0.42\n",
      "60\tValid loss: 1.3940\tBest loss: 1.3024\tACC: 0.47\n",
      "61\tValid loss: 1.7115\tBest loss: 1.3024\tACC: 0.45\n",
      "62\tValid loss: 1.7873\tBest loss: 1.3024\tACC: 0.47\n",
      "63\tValid loss: 1.6183\tBest loss: 1.3024\tACC: 0.50\n",
      "64\tValid loss: 1.9580\tBest loss: 1.3024\tACC: 0.51\n",
      "65\tValid loss: 1.5321\tBest loss: 1.3024\tACC: 0.50\n",
      "66\tValid loss: 1.5628\tBest loss: 1.3024\tACC: 0.51\n",
      "67\tValid loss: 1.7562\tBest loss: 1.3024\tACC: 0.52\n",
      "68\tValid loss: 1.6445\tBest loss: 1.3024\tACC: 0.49\n",
      "69\tValid loss: 1.4979\tBest loss: 1.3024\tACC: 0.57\n",
      "70\tValid loss: 1.7903\tBest loss: 1.3024\tACC: 0.41\n",
      "71\tValid loss: 1.2885\tBest loss: 1.2885\tACC: 0.51\n",
      "72\tValid loss: 1.9270\tBest loss: 1.2885\tACC: 0.37\n",
      "73\tValid loss: 1.3511\tBest loss: 1.2885\tACC: 0.58\n",
      "74\tValid loss: 1.6061\tBest loss: 1.2885\tACC: 0.43\n",
      "75\tValid loss: 1.7449\tBest loss: 1.2885\tACC: 0.45\n",
      "76\tValid loss: 1.7052\tBest loss: 1.2885\tACC: 0.54\n",
      "77\tValid loss: 1.7994\tBest loss: 1.2885\tACC: 0.48\n",
      "78\tValid loss: 1.9525\tBest loss: 1.2885\tACC: 0.45\n",
      "79\tValid loss: 1.8906\tBest loss: 1.2885\tACC: 0.47\n",
      "80\tValid loss: 1.3645\tBest loss: 1.2885\tACC: 0.53\n",
      "81\tValid loss: 1.3898\tBest loss: 1.2885\tACC: 0.49\n",
      "82\tValid loss: 1.5424\tBest loss: 1.2885\tACC: 0.55\n",
      "83\tValid loss: 1.4126\tBest loss: 1.2885\tACC: 0.51\n",
      "84\tValid loss: 1.6952\tBest loss: 1.2885\tACC: 0.53\n",
      "85\tValid loss: 1.9993\tBest loss: 1.2885\tACC: 0.50\n",
      "86\tValid loss: 1.7025\tBest loss: 1.2885\tACC: 0.44\n",
      "87\tValid loss: 1.7933\tBest loss: 1.2885\tACC: 0.57\n",
      "88\tValid loss: 1.8541\tBest loss: 1.2885\tACC: 0.41\n",
      "89\tValid loss: 1.8900\tBest loss: 1.2885\tACC: 0.47\n",
      "90\tValid loss: 1.7229\tBest loss: 1.2885\tACC: 0.54\n",
      "91\tValid loss: 1.2206\tBest loss: 1.2206\tACC: 0.55\n",
      "92\tValid loss: 2.1115\tBest loss: 1.2206\tACC: 0.53\n",
      "93\tValid loss: 1.9404\tBest loss: 1.2206\tACC: 0.48\n",
      "94\tValid loss: 1.5025\tBest loss: 1.2206\tACC: 0.55\n",
      "95\tValid loss: 1.6025\tBest loss: 1.2206\tACC: 0.52\n",
      "96\tValid loss: 1.5418\tBest loss: 1.2206\tACC: 0.49\n",
      "97\tValid loss: 1.6307\tBest loss: 1.2206\tACC: 0.51\n",
      "98\tValid loss: 1.5902\tBest loss: 1.2206\tACC: 0.56\n",
      "99\tValid loss: 1.2620\tBest loss: 1.2206\tACC: 0.54\n",
      "100\tValid loss: 1.5953\tBest loss: 1.2206\tACC: 0.53\n",
      "101\tValid loss: 1.6243\tBest loss: 1.2206\tACC: 0.47\n",
      "102\tValid loss: 1.4141\tBest loss: 1.2206\tACC: 0.53\n",
      "103\tValid loss: 1.5571\tBest loss: 1.2206\tACC: 0.47\n",
      "104\tValid loss: 1.5955\tBest loss: 1.2206\tACC: 0.45\n",
      "105\tValid loss: 1.7182\tBest loss: 1.2206\tACC: 0.43\n",
      "106\tValid loss: 2.2228\tBest loss: 1.2206\tACC: 0.44\n",
      "107\tValid loss: 1.4136\tBest loss: 1.2206\tACC: 0.56\n",
      "108\tValid loss: 1.4967\tBest loss: 1.2206\tACC: 0.57\n",
      "109\tValid loss: 1.7346\tBest loss: 1.2206\tACC: 0.48\n",
      "110\tValid loss: 1.9243\tBest loss: 1.2206\tACC: 0.45\n",
      "111\tValid loss: 1.2348\tBest loss: 1.2206\tACC: 0.51\n",
      "Early stop triggered\n",
      "Training time: 8.8sec\n",
      "INFO:tensorflow:Restoring parameters from ./Team11_HW3_3.ckpt\n",
      "test acc:  0.5116\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 30\n",
    "#early stop if no progress in 20 epochs\n",
    "early_stop_trigger_step = 20\n",
    "early_stop_cnt = 0\n",
    "best_loss = np.infty\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    restore_saver.restore(sess, \"./model/Team11_HW2.ckpt\")\n",
    "    \n",
    "#     for var in output_layer_vars:\n",
    "#         var.initializer.run()\n",
    "    \n",
    "    t0 = time.time()\n",
    "    #start training and print each epoch\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_idxs in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_idxs], y_train2[rnd_idxs]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "            if early_stop_cnt > early_stop_trigger_step:\n",
    "                save_path = four_frozen_saver.save(sess, \"./Team11_HW3_3.ckpt\")\n",
    "                print(\"Early stop triggered\")\n",
    "                break\n",
    "        print(\"{}\\tValid loss: {:.4f}\\tBest loss: {:.4f}\\tACC: {:.2f}\".format(\n",
    "            epoch, loss_val, best_loss, acc_val))\n",
    "    t1 = time.time()\n",
    "    print(\"Training time: {:.1f}sec\".format(t1 - t0))\n",
    "with tf.Session() as sess:\n",
    "    four_frozen_saver.restore(sess, \"./Team11_HW3_3.ckpt\")\n",
    "    #use full instance per class for testing set\n",
    "    acc_test = sess.run(accuracy,feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test acc:  {:.4f}\".format(acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW3.4  Unfreeze top 2 layers.\n",
    "Result testing set accuracy is better than all method above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "unfrozen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"hidden[34]|new_logits\")\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate, name=\"Adam3\")\n",
    "training_op = optimizer.minimize(loss, var_list=unfrozen_vars)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "two_frozen_saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./Team11_HW3_3.ckpt\n",
      "0\tValid loss: 2.2020\tBest loss: 2.2020\tACC: 0.49\n",
      "1\tValid loss: 1.7333\tBest loss: 1.7333\tACC: 0.53\n",
      "2\tValid loss: 1.8713\tBest loss: 1.7333\tACC: 0.49\n",
      "3\tValid loss: 1.6853\tBest loss: 1.6853\tACC: 0.43\n",
      "4\tValid loss: 1.1794\tBest loss: 1.1794\tACC: 0.57\n",
      "5\tValid loss: 1.4784\tBest loss: 1.1794\tACC: 0.48\n",
      "6\tValid loss: 1.8281\tBest loss: 1.1794\tACC: 0.45\n",
      "7\tValid loss: 1.1877\tBest loss: 1.1794\tACC: 0.55\n",
      "8\tValid loss: 1.3865\tBest loss: 1.1794\tACC: 0.47\n",
      "9\tValid loss: 1.0211\tBest loss: 1.0211\tACC: 0.54\n",
      "10\tValid loss: 1.3133\tBest loss: 1.0211\tACC: 0.55\n",
      "11\tValid loss: 1.2680\tBest loss: 1.0211\tACC: 0.50\n",
      "12\tValid loss: 1.2298\tBest loss: 1.0211\tACC: 0.52\n",
      "13\tValid loss: 1.1892\tBest loss: 1.0211\tACC: 0.58\n",
      "14\tValid loss: 1.1658\tBest loss: 1.0211\tACC: 0.54\n",
      "15\tValid loss: 1.1435\tBest loss: 1.0211\tACC: 0.48\n",
      "16\tValid loss: 1.0880\tBest loss: 1.0211\tACC: 0.57\n",
      "17\tValid loss: 1.1188\tBest loss: 1.0211\tACC: 0.59\n",
      "18\tValid loss: 1.0563\tBest loss: 1.0211\tACC: 0.58\n",
      "19\tValid loss: 0.9861\tBest loss: 0.9861\tACC: 0.61\n",
      "20\tValid loss: 1.1653\tBest loss: 0.9861\tACC: 0.58\n",
      "21\tValid loss: 1.0576\tBest loss: 0.9861\tACC: 0.57\n",
      "22\tValid loss: 0.9734\tBest loss: 0.9734\tACC: 0.63\n",
      "23\tValid loss: 1.0266\tBest loss: 0.9734\tACC: 0.59\n",
      "24\tValid loss: 1.0596\tBest loss: 0.9734\tACC: 0.59\n",
      "25\tValid loss: 1.0664\tBest loss: 0.9734\tACC: 0.55\n",
      "26\tValid loss: 1.0761\tBest loss: 0.9734\tACC: 0.60\n",
      "27\tValid loss: 1.1556\tBest loss: 0.9734\tACC: 0.55\n",
      "28\tValid loss: 1.1256\tBest loss: 0.9734\tACC: 0.61\n",
      "29\tValid loss: 1.0943\tBest loss: 0.9734\tACC: 0.55\n",
      "30\tValid loss: 1.1632\tBest loss: 0.9734\tACC: 0.53\n",
      "31\tValid loss: 1.0280\tBest loss: 0.9734\tACC: 0.58\n",
      "32\tValid loss: 1.0480\tBest loss: 0.9734\tACC: 0.57\n",
      "33\tValid loss: 1.0943\tBest loss: 0.9734\tACC: 0.53\n",
      "34\tValid loss: 1.0680\tBest loss: 0.9734\tACC: 0.59\n",
      "35\tValid loss: 1.1350\tBest loss: 0.9734\tACC: 0.51\n",
      "36\tValid loss: 1.0261\tBest loss: 0.9734\tACC: 0.59\n",
      "37\tValid loss: 1.0268\tBest loss: 0.9734\tACC: 0.61\n",
      "38\tValid loss: 1.1314\tBest loss: 0.9734\tACC: 0.57\n",
      "39\tValid loss: 1.0932\tBest loss: 0.9734\tACC: 0.65\n",
      "40\tValid loss: 1.1941\tBest loss: 0.9734\tACC: 0.54\n",
      "41\tValid loss: 1.1125\tBest loss: 0.9734\tACC: 0.51\n",
      "42\tValid loss: 0.9886\tBest loss: 0.9734\tACC: 0.59\n",
      "Early stop triggered\n",
      "INFO:tensorflow:Restoring parameters from ./Team11_HW3_4.ckpt\n",
      "test acc:  0.5369\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "batch_size = 30\n",
    "#early stop if no progress in 20 epochs\n",
    "early_stop_trigger_step = 20\n",
    "early_stop_cnt = 0\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    four_frozen_saver.restore(sess, \"./Team11_HW3_3.ckpt\")\n",
    "    best_loss = np.infty\n",
    "    for epoch in range(n_epochs):\n",
    "        rnd_idx = np.random.permutation(len(X_train2))\n",
    "        for rnd_idxs in np.array_split(rnd_idx, len(X_train2) // batch_size):\n",
    "            X_batch, y_batch = X_train2[rnd_idxs], y_train2[rnd_idxs]\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        loss_val, acc_val = sess.run([loss, accuracy], feed_dict={X: X_valid2, y: y_valid2})\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "            if early_stop_cnt > early_stop_trigger_step:\n",
    "                save_path = two_frozen_saver.save(sess, \"./Team11_HW3_4.ckpt\")\n",
    "                print(\"Early stop triggered\")\n",
    "                break\n",
    "        print(\"{}\\tValid loss: {:.4f}\\tBest loss: {:.4f}\\tACC: {:.2f}\".format(\n",
    "            epoch, loss_val, best_loss, acc_val))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    two_frozen_saver.restore(sess, \"./Team11_HW3_4.ckpt\")\n",
    "    acc_test = sess.run(accuracy,feed_dict={X: X_test2, y: y_test2})\n",
    "    print(\"test acc:  {:.4f}\".format(acc_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
