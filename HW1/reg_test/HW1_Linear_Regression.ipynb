{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 1)\n",
      "Done!\n",
      "\n",
      "Running test...\n",
      "\n",
      "loss =[ 0.52663017]\n",
      "Real value Y: [ 0.894]\n",
      "Pred Y: [[ 0.6155417]]\n",
      "Ran 20599times\n",
      "W=[[ 0.86063749]\n",
      " [ 0.12959577]\n",
      " [-0.32296914]\n",
      " [ 0.3319644 ]\n",
      " [-0.00215462]\n",
      " [-0.0464987 ]\n",
      " [-0.76465362]\n",
      " [-0.73907274]]\n",
      "b=[ 2.06839871]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import pandas as pd \n",
    "from __future__ import print_function\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    Return a total of `num` random samples and labels. \n",
    "    '''\n",
    "    #get n random index\n",
    "    idx = np.arange(0 , len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx = idx[:num]\n",
    "    ####\n",
    "    data_shuffle = [data[ i] for i in idx]\n",
    "    labels_shuffle = [labels[ i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "###### Implement Data Preprocess here ######\n",
    "dataset = fetch_california_housing(data_home='./')\n",
    "M = dataset.data.shape[0]\n",
    "# normalized data\n",
    "dataset.data -= np.mean(dataset.data, axis=0)\n",
    "dataset.data /= np.std(dataset.data, axis=0)\n",
    "###### End Data Preprocess ######\n",
    "dataset.target=dataset.target.reshape([M, 1])\n",
    "print(dataset.target.shape)\n",
    "###### Start TF session ######\n",
    "learning_rate = 0.001\n",
    "batch_size = 100\n",
    "\n",
    "# Create the model\n",
    "Y = tf.placeholder(tf.float32,[None,1],name = 'Y')\n",
    "X = tf.placeholder(tf.float32, [None,8],name = 'X_in')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([8,1]),name = 'n_Weight' )\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis  = tf.add(tf.matmul(X, W), b)\n",
    "loss = tf.reduce_sum(tf.square(hypothesis  - Y)) / (batch_size)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Run the initializer\n",
    "    init = tf.global_variables_initializer() \n",
    "    sess.run(init)\n",
    "    # Fit all training data\n",
    "\n",
    "    batch_count = int(M/batch_size)\n",
    "    for i in range(batch_count*10):\n",
    "        Xtr, Ytr = next_batch(batch_size, dataset.data, dataset.target)\n",
    "        _, loss_val, hypo = sess.run(\n",
    "            [train_op, loss, hypothesis],\n",
    "            feed_dict={X:Xtr,Y:Ytr})\n",
    "\n",
    "    print(\"Done!\\n\")\n",
    "    print(\"Running test...\\n\")\n",
    "\n",
    "    t=0\n",
    "    W_final = sess.run(W)\n",
    "    b_final = sess.run(b)\n",
    "    for pred_n in range(M):\n",
    "        t = t+np.power(np.matmul(dataset.data[pred_n],W_final)+b_final-dataset.target[pred_n],2)\n",
    "    print(\"loss =\" + str(t/M))\n",
    "    print(\"Ran \" + str(i) + \"times\\nW=\" + str(W_final)+ \"\\nb=\" + str(sess.run(b_final)) )\n",
    "\n",
    "\n",
    "###### Start TF session ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594287337897\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import pandas as pd \n",
    "from __future__ import print_function\n",
    "\n",
    "dataset = fetch_california_housing(data_home='./')\n",
    "M = dataset.data.shape[0]\n",
    "\n",
    "wl = [0.50891769,0.01526526,-0.17812857,0.85301304,7.21363449*0.000001,-0.00464269,-0.08619303,-0.04299315]\n",
    "wl = np.transpose(wl)\n",
    "b=-2.37039804\n",
    "t=0\n",
    "\n",
    "for pred_n in range(M):\n",
    "    t = t+np.power(np.matmul(dataset.data[pred_n],wl)+b-dataset.target[pred_n],2)\n",
    "print(t/M)\n",
    "\n",
    "#     show_graph(tf.get_default_graph().as_graph_def())\n",
    "###### Start TF session ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.7826994   1.85618152  1.15562047 -0.04901636 -0.82077735 -0.02584253\n",
      "   1.03850269 -1.33282653]]\n",
      "3.521\n"
     ]
    }
   ],
   "source": [
    "print(dataset.data[2, :].reshape([1, 8]))\n",
    "print(dataset.target[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of dataset: (20640, 8)\n",
      "Shape of label: (20640,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "      <td>20640.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.870671</td>\n",
       "      <td>28.639486</td>\n",
       "      <td>5.429000</td>\n",
       "      <td>1.096675</td>\n",
       "      <td>1425.476744</td>\n",
       "      <td>3.070655</td>\n",
       "      <td>35.631861</td>\n",
       "      <td>-119.569704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.899822</td>\n",
       "      <td>12.585558</td>\n",
       "      <td>2.474173</td>\n",
       "      <td>0.473911</td>\n",
       "      <td>1132.462122</td>\n",
       "      <td>10.386050</td>\n",
       "      <td>2.135952</td>\n",
       "      <td>2.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499900</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>32.540000</td>\n",
       "      <td>-124.350000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.563400</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>4.440716</td>\n",
       "      <td>1.006079</td>\n",
       "      <td>787.000000</td>\n",
       "      <td>2.429741</td>\n",
       "      <td>33.930000</td>\n",
       "      <td>-121.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.534800</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>5.229129</td>\n",
       "      <td>1.048780</td>\n",
       "      <td>1166.000000</td>\n",
       "      <td>2.818116</td>\n",
       "      <td>34.260000</td>\n",
       "      <td>-118.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.743250</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>6.052381</td>\n",
       "      <td>1.099526</td>\n",
       "      <td>1725.000000</td>\n",
       "      <td>3.282261</td>\n",
       "      <td>37.710000</td>\n",
       "      <td>-118.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15.000100</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>141.909091</td>\n",
       "      <td>34.066667</td>\n",
       "      <td>35682.000000</td>\n",
       "      <td>1243.333333</td>\n",
       "      <td>41.950000</td>\n",
       "      <td>-114.310000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
       "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
       "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
       "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
       "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
       "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
       "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
       "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
       "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
       "\n",
       "           AveOccup      Latitude     Longitude  \n",
       "count  20640.000000  20640.000000  20640.000000  \n",
       "mean       3.070655     35.631861   -119.569704  \n",
       "std       10.386050      2.135952      2.003532  \n",
       "min        0.692308     32.540000   -124.350000  \n",
       "25%        2.429741     33.930000   -121.800000  \n",
       "50%        2.818116     34.260000   -118.490000  \n",
       "75%        3.282261     37.710000   -118.010000  \n",
       "max     1243.333333     41.950000   -114.310000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn import linear_model\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "import pandas as pd \n",
    "\n",
    "dataset = fetch_california_housing(data_home='../',download_if_missing=False)\n",
    "print(\"Shape of dataset:\", dataset.data.shape)\n",
    "print(\"Shape of label:\", dataset.target.shape)\n",
    "\n",
    "X_org, Y_org = dataset.data, dataset.target\n",
    "df_x=pd.DataFrame(dataset.data,columns=dataset.feature_names)\n",
    "df_y=pd.DataFrame(dataset.target)\n",
    "df_x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  8.32520000e+00   4.10000000e+01   6.98412698e+00   1.02380952e+00\n",
      "    3.22000000e+02   2.55555556e+00   3.78800000e+01  -1.22230000e+02]\n",
      " [  8.30140000e+00   2.10000000e+01   6.23813708e+00   9.71880492e-01\n",
      "    2.40100000e+03   2.10984183e+00   3.78600000e+01  -1.22220000e+02]\n",
      " [  7.25740000e+00   5.20000000e+01   8.28813559e+00   1.07344633e+00\n",
      "    4.96000000e+02   2.80225989e+00   3.78500000e+01  -1.22240000e+02]\n",
      " [  5.64310000e+00   5.20000000e+01   5.81735160e+00   1.07305936e+00\n",
      "    5.58000000e+02   2.54794521e+00   3.78500000e+01  -1.22250000e+02]\n",
      " [  3.84620000e+00   5.20000000e+01   6.28185328e+00   1.08108108e+00\n",
      "    5.65000000e+02   2.18146718e+00   3.78500000e+01  -1.22250000e+02]\n",
      " [  4.03680000e+00   5.20000000e+01   4.76165803e+00   1.10362694e+00\n",
      "    4.13000000e+02   2.13989637e+00   3.78500000e+01  -1.22250000e+02]\n",
      " [  3.65910000e+00   5.20000000e+01   4.93190661e+00   9.51361868e-01\n",
      "    1.09400000e+03   2.12840467e+00   3.78400000e+01  -1.22250000e+02]\n",
      " [  3.12000000e+00   5.20000000e+01   4.79752705e+00   1.06182380e+00\n",
      "    1.15700000e+03   1.78825348e+00   3.78400000e+01  -1.22250000e+02]\n",
      " [  2.08040000e+00   4.20000000e+01   4.29411765e+00   1.11764706e+00\n",
      "    1.20600000e+03   2.02689076e+00   3.78400000e+01  -1.22260000e+02]]\n"
     ]
    }
   ],
   "source": [
    "print(dataset.data[0:9,0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init cost= 481.076019287 W= [[ 0.]\n",
      " [ 0.]] b= [ 0.]\n",
      "Epoch: 1000 cost= 69.765686035 W= [[ 2.67665052]\n",
      " [ 1.63108909]] b= [ 2.00915909]\n",
      "Epoch: 2000 cost= 66.036315918 W= [[ 2.49362659]\n",
      " [ 1.50724256]] b= [ 3.3563478]\n",
      "Epoch: 3000 cost= 62.819210052 W= [[ 2.31633854]\n",
      " [ 1.39988863]] b= [ 4.60731697]\n",
      "Epoch: 4000 cost= 60.043563843 W= [[ 2.15154791]\n",
      " [ 1.30029368]] b= [ 5.76928186]\n",
      "Epoch: 5000 cost= 57.648818970 W= [[ 1.99847889]\n",
      " [ 1.20778537]] b= [ 6.84858418]\n",
      "Epoch: 6000 cost= 55.582687378 W= [[ 1.85629892]\n",
      " [ 1.12185991]] b= [ 7.85109806]\n",
      "Epoch: 7000 cost= 53.800094604 W= [[ 1.72423553]\n",
      " [ 1.04204738]] b= [ 8.78228569]\n",
      "Epoch: 8000 cost= 52.262104034 W= [[ 1.60156739]\n",
      " [ 0.9679119 ]] b= [ 9.64723015]\n",
      "Epoch: 9000 cost= 50.935176849 W= [[ 1.48762643]\n",
      " [ 0.89905107]] b= [ 10.45063877]\n",
      "Epoch: 10000 cost= 49.790321350 W= [[ 1.38179076]\n",
      " [ 0.83508903]] b= [ 11.19689274]\n",
      "Epoch: 11000 cost= 48.802577972 W= [[ 1.28348505]\n",
      " [ 0.7756775 ]] b= [ 11.8900547]\n",
      "Epoch: 12000 cost= 47.950386047 W= [[ 1.19217384]\n",
      " [ 0.72049344]] b= [ 12.53389835]\n",
      "Epoch: 13000 cost= 47.215137482 W= [[ 1.10735834]\n",
      " [ 0.66923487]] b= [ 13.13193607]\n",
      "Epoch: 14000 cost= 46.580780029 W= [[ 1.02857709]\n",
      " [ 0.6216231 ]] b= [ 13.68743038]\n",
      "Epoch: 15000 cost= 46.033470154 W= [[ 0.95540041]\n",
      " [ 0.57739919]] b= [ 14.20340061]\n",
      "Epoch: 16000 cost= 45.561267853 W= [[ 0.88743013]\n",
      " [ 0.53632116]] b= [ 14.68266296]\n",
      "Epoch: 17000 cost= 45.153865814 W= [[ 0.82429558]\n",
      " [ 0.49816567]] b= [ 15.12782955]\n",
      "Epoch: 18000 cost= 44.802368164 W= [[ 0.76565284]\n",
      " [ 0.4627243 ]] b= [ 15.54132652]\n",
      "Epoch: 19000 cost= 44.499111176 W= [[ 0.71118176]\n",
      " [ 0.42980459]] b= [ 15.92540455]\n",
      "Epoch: 20000 cost= 44.237461090 W= [[ 0.66058612]\n",
      " [ 0.39922705]] b= [ 16.28215408]\n",
      "Optimization Finished!\n",
      "Training cost= 44.2375 W= [[ 0.66058612]\n",
      " [ 0.39922705]] b= [ 16.28215408] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "A linear regression learning algorithm example using TensorFlow library.\n",
    "Author: Aymeric Damien\n",
    "Project: https://github.com/aymericdamien/TensorFlow-Examples/\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "\n",
    "def init_weights(shape):\n",
    "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
    "# Parameters\n",
    "learning_rate = 0.0005\n",
    "training_epochs = 20000\n",
    "display_step = 1000\n",
    "\n",
    "# Training Data\n",
    "train_X = numpy.asarray([[2.2,3.5,4.7,6.8,5.5,3.4,2.7,6.1,5.3,1.9],\n",
    "                         [5.7,6.2,5.5,1.2,0.8,4.7,2.0,3.8,6.6,1.9]])\n",
    "train_Y = numpy.asarray([22.5,26.6,26.9,18.2,14.4,21.9,12.4,24.6,31.4,10.5])\n",
    "train_X = numpy.transpose(train_X)\n",
    "train_Y = numpy.transpose(train_Y)\n",
    "\n",
    "\n",
    "\n",
    "# Create the model\n",
    "X = tf.placeholder(tf.float32, [None,2])\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# W = tf.Variable(tf.random([2, 1]))\n",
    "W = tf.Variable([[0.0],[0.0]])\n",
    "b = tf.Variable([0.0])\n",
    "pred = tf.matmul(X, W) + b\n",
    "\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_mean(tf.square(pred-Y))\n",
    "# Gradient descent\n",
    "#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "    print(\"Init cost=\", \"{:.9f}\".format(c), \\\n",
    "        \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "        sess.run(optimizer, feed_dict={X: train_X, Y: train_Y})\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "#     # Graphic display\n",
    "#     plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "#     plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "#     plt.legend()\n",
    "#     plt.show()\n",
    "\n",
    "#     # Testing example, as requested (Issue #2)\n",
    "#     test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n",
    "#     test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n",
    "\n",
    "#     print(\"Testing... (Mean square loss Comparison)\")\n",
    "#     testing_cost = sess.run(\n",
    "#         tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\n",
    "#         feed_dict={X: test_X, Y: test_Y})  # same function as cost above\n",
    "#     print(\"Testing cost=\", testing_cost)\n",
    "#     print(\"Absolute mean square loss difference:\", abs(\n",
    "#         training_cost - testing_cost))\n",
    "\n",
    "#     plt.plot(test_X, test_Y, 'bo', label='Testing data')\n",
    "#     plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10000 cost= 157.135894775 W= -2.22251 b= -0.539712\n",
      "Epoch: 0050 cost= 0.128532469 W= 0.380424 b= -0.114257\n",
      "Epoch: 0100 cost= 0.122630529 W= 0.372836 b= -0.0604586\n",
      "Epoch: 0150 cost= 0.117403604 W= 0.365695 b= -0.00983007\n",
      "Epoch: 0200 cost= 0.112774491 W= 0.358974 b= 0.0378154\n",
      "Epoch: 0250 cost= 0.108674794 W= 0.352649 b= 0.0826535\n",
      "Epoch: 0300 cost= 0.105044000 W= 0.346698 b= 0.12485\n",
      "Epoch: 0350 cost= 0.101828426 W= 0.341096 b= 0.16456\n",
      "Epoch: 0400 cost= 0.098980658 W= 0.335825 b= 0.20193\n",
      "Epoch: 0450 cost= 0.096458599 W= 0.330865 b= 0.237098\n",
      "Epoch: 0500 cost= 0.094224960 W= 0.326196 b= 0.270194\n",
      "Epoch: 0550 cost= 0.092246808 W= 0.321803 b= 0.301341\n",
      "Epoch: 0600 cost= 0.090494864 W= 0.317669 b= 0.330652\n",
      "Epoch: 0650 cost= 0.088943303 W= 0.313778 b= 0.358235\n",
      "Epoch: 0700 cost= 0.087569207 W= 0.310116 b= 0.384194\n",
      "Epoch: 0750 cost= 0.086352259 W= 0.306671 b= 0.408623\n",
      "Epoch: 0800 cost= 0.085274518 W= 0.303428 b= 0.431613\n",
      "Epoch: 0850 cost= 0.084320009 W= 0.300376 b= 0.453248\n",
      "Epoch: 0900 cost= 0.083474673 W= 0.297504 b= 0.473608\n",
      "Epoch: 0950 cost= 0.082726039 W= 0.294802 b= 0.492769\n",
      "Epoch: 1000 cost= 0.082063004 W= 0.292258 b= 0.510801\n",
      "Optimization Finished!\n",
      "Training cost= 0.082063 W= 0.292258 b= 0.510801 \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt0VNX5N/DvQwiEQBC5KAiEiRCFcAsQuUUtEJBrvaBY\nLNVKq4hSpW8RiwYVwQBWC7U/RRqLIq/56YsoQgWpN+4UNEGuAYFIiAFEwHIJIRCS5/1jhiFnmJBJ\nMjPnzJnvZ62s5OzszHnWsPhmZ5999hFVBRER2UsNswsgIiL/Y7gTEdkQw52IyIYY7kRENsRwJyKy\nIYY7EZENMdyJiGyI4U5EZEMMdyIiG6pp1okbN26sDofDrNMTEYWkrKysY6rapKJ+poW7w+FAZmam\nWacnIgpJInLAl36cliEisiGGOxGRDTHciYhsyLQ5d2+Ki4uRn5+PoqIis0shAFFRUWjRogUiIyPN\nLoWIKslS4Z6fn4+YmBg4HA6IiNnlhDVVxfHjx5Gfn4+4uDizyyGiSrLUtExRUREaNWrEYLcAEUGj\nRo34VxRRiLJUuANgsFsI/y2IQpflwp2IyK6Kiksw6/M9OHTibMDPxXD3kJ+fjzvuuAPx8fFo3bo1\nxo8fj/Pnz3vte+jQIdxzzz0VvuaQIUNw4sSJKtUzZcoUvPLKKxX2q1ev3hW/f+LECcyZM6dKNRBR\n9S3M/AFtn12Bv3+5F2v2HA34+UI73DMyAIcDqFHD+Tkjo1ovp6oYPnw47rzzTuzduxd79uxBQUEB\nUlNTL+t74cIFXHfddVi0aFGFr7t8+XI0aNCgWrVVF8OdyBwnzxbDMWkZnlq0DQBwZ+J1GNk9NuDn\nDd1wz8gAxowBDhwAVJ2fx4ypVsB/9dVXiIqKwujRowEAERERmD17Nt566y0UFhZi/vz5uP3229Gv\nXz+kpKQgNzcXHTp0AAAUFhbi3nvvRUJCAu666y706NHDvb2Cw+HAsWPHkJubi3bt2uHhhx9G+/bt\ncdttt+HsWeefZ2+++SZuuukmdO7cGXfffTcKCwuvWOv+/fvRq1cvdOzYEZMnT3a3FxQUICUlBV27\ndkXHjh2xZMkSAMCkSZOQk5ODxMRETJw4sdx+ROQ/c1fnoPMLn7mP10zsi7+N7BKUc4duuKemAp4B\nWFjobK+inTt3olu3boa2+vXrIzY2Fvv27QMAbN68GYsWLcLq1asN/ebMmYOrr74a2dnZmDZtGrKy\nsryeY+/evRg3bhx27tyJBg0a4MMPPwQADB8+HN988w22bt2Kdu3aYd68eVesdfz48Xj00Uexfft2\nNGvWzN0eFRWFxYsXY/PmzVi5ciUmTJgAVcXMmTPRunVrbNmyBS+//HK5/Yio+n46VQTHpGWY+elu\nAMAjt16P3JlDEdsoOmg1WGqde6Xk5VWu3U8GDBiAhg0bXta+bt06jB8/HgDQoUMHdOrUyevPx8XF\nITExEQDQrVs35ObmAgB27NiByZMn48SJEygoKMDAgQOvWMf69evdvxjuv/9+/PnPfwbgnFp65pln\nsGbNGtSoUQMHDx7EkSNHLvv58vo1bdrUtzeCiLya9kk25q3b7z7+JrU/msTUDnodoRvusbHOqRhv\n7VWUkJBw2Rz6qVOnkJeXhzZt2mDz5s2oW7dulV8fAGrXvvSPHBER4Z6WefDBB/Hxxx+jc+fOmD9/\nPlatWlXha3lbqpiRkYGjR48iKysLkZGRcDgcXteq+9qPiHyTe+wM+ryyyn2cOqQdHr71etPqCd1p\nmbQ0INrjT5zoaGd7FaWkpKCwsBALFiwAAJSUlGDChAl48MEHEe15Lg/JyclYuHAhACA7Oxvbt2+v\n1LlPnz6NZs2aobi4GBk+XDdITk7G+++/DwCG/idPnsQ111yDyMhIrFy5EgdcvwBjYmJw+vTpCvsR\nUeU9/t63hmDfNuU2U4MdCOVwHzUKSE8HWrUCRJyf09Od7VUkIli8eDE++OADxMfH44YbbkBUVBSm\nT59e4c8+9thjOHr0KBISEjB58mS0b98eV111lc/nnjZtGnr06IHk5GS0bdu2wv6vvvoqXn/9dXTs\n2BEHDx50t48aNQqZmZno2LEjFixY4H6tRo0aITk5GR06dMDEiRPL7UdEvttx8CQck5bhX1sPAQBe\nGdEZuTOHon6U+fsxiVkX0ZKSktTzYR27du1Cu3btTKmnukpKSlBcXIyoqCjk5OSgf//++O6771Cr\nVi2zS6uWUP43IQqU0lLFyPSN+Dr3ZwDA1dGR+M/TKYiKjAj4uUUkS1WTKupX4Zy7iEQBWAOgtqv/\nIlV93qNPHwBLAFy8ivCRqk6tbNGhrLCwEH379kVxcTFUFXPmzAn5YCeiy23IOYZfv7nJffzWg0no\n1/ZaEyvyzpcLqucA9FPVAhGJBLBORD5V1Y0e/daq6jD/lxgaYmJi+NhAIhsrLilF/1mrceC4cwl2\n26YxWPbELYioYc09mCoMd3XO2xS4DiNdH1wQTURhY8WOwxj77mb38aKxvZDkuHxJtJX4tBRSRCIA\nZAFoA+B1Vd3kpVtvEdkG4CCAJ1V1p//KJCIKvrPnS9Bl2mcoKi4FANx6QxO8M/qmkNgx1afVMqpa\noqqJAFoA6C4iHTy6bAYQq6qdAPwPgI+9vY6IjBGRTBHJPHo08BvnEBFV1f9uykO751a4g/3ff7wV\nC37XvXrB7uf9sK6kUjcxqeoJEVkJYBCAHWXaT5X5ermIzBGRxqp6zOPn0wGkA87VMtWqnIgoAE4U\nnkfi1M/dxyO6tcDLIzpX/4Uv7od1cduUi/thAdVawl2eCkfuItJERBq4vq4DYACA3R59morr15mI\ndHe97nG/VxsEERERSExMdH/k5uYiMzMTTzzxBABg1apV2LBhg7v/xx9/jOzs7Eqfp7wtei+2+7qd\nMBH5z2tf7TUE+9qn+von2IGA7Id1Jb6M3JsBeMc1714DwEJV/URExgKAqs4FcA+AR0XkAoCzAEZq\niO5CVadOHWzZssXQ5nA4kJTkXFa6atUq1KtXD7179wbgDPdhw4YhISHBr3X4up0wEVXfjyeL0HPG\nl+7jcX1bY+JAP9/YF+T9sCocuavqNlXtoqqdVLXDxfXrqjrXFexQ1ddUtb2qdlbVnqq64cqvGlpW\nrVqFYcOGITc3F3PnzsXs2bORmJiI1atXY+nSpZg4cSISExORk5ODnJwcDBo0CN26dcMtt9yC3bud\nf+SUt0VvecpuJzx//nwMHz4cgwYNQnx8PJ566il3v88++wy9evVC165dMWLECBQUFJT3kkTkxfNL\ndhiCPWtyf/8HO1D+vlfV2A/rSiy7cdgL/9qJ7EOnKu5YCQnX1cfzv2x/xT5nz55179oYFxeHxYsX\nu7/ncDgwduxY1KtXD08++SQA4Pbbb8ewYcPcUygpKSmYO3cu4uPjsWnTJjz22GP46quv3Fv0PvDA\nA3j99dcrXfuWLVvw7bffonbt2rjxxhvx+OOPo06dOnjxxRfxxRdfoG7dunjppZcwa9YsPPfcc5V+\nfaJwk3O0ACl/vbR193PDEvC7m+MCd8K0NOOcO1Dt/bCuxLLhbhZv0zK+KigowIYNGzBixAh327lz\n5wCUv0Wvr1JSUtx71SQkJODAgQM4ceIEsrOzkZycDAA4f/48evXqVaXaicKFquLRdzdjxc4f3W07\nXhiIerUDHIcXL5qmpjqnYmJjncEegIupgIXDvaIRthWVlpaiQYMG5f5yqM4SKs+tgi9cuABVxYAB\nA/Dee+9V+XWJwsm2/BO4/bX17uNXRybijsTmwStg1KiAhbmn0N0V0iSeW+eWPa5fvz7i4uLwwQcf\nAHCOELZu3Qqg/C16q6Nnz55Yv369+ylRZ86cwZ49e/zy2kS24FpXXlojAnc+9Jo72K+JqY3vXhwU\n3GAPMoZ7Jf3yl7/E4sWLkZiYiLVr12LkyJF4+eWX0aVLF+Tk5CAjIwPz5s1D586d0b59e/ezScvb\norc6mjRpgvnz5+O+++5Dp06d0KtXL/cFXKKw51pX/o9ru+H6p5ZiS2PnfPp8RwG+Tu2P2jUDv4Oj\nmbjlL10R/00oVBW2vgEJI2a7jzse3ouP/+8ERMS2BFyPtwxFftvyl4go1DyWkYXlZYL9+S/+gdFZ\n/3IeBPg5y1bBcCci2zhWcA5JL35haNv/0jAYljIEaF251Vgu3FU1JHZcCwchepMxhalBf1uD3T9e\nWuzwRuwZDJ442tgpgOvKrcZS4R4VFYXjx4+jUaNGDHiTqSqOHz+OqKgos0shuqLvjxagX5mbkQAg\nd+ZQ5xdXFQdtXbnVWOqCanFxMfLz81FUVGRKTWQUFRWFFi1aIDLS/If9EnnjmLTMcPzho73QrZW1\nH6JRXSF5QTUyMhJxcQG8/ZeIbCHrwM+4+43/GNrco3UCYLFwJyKqiOdo/csJv0DrJt630A5nDHci\nCgmezzGNv6YePv/TL0ysyNoY7kRkaaqKuKeXG9q+Se2PJjG1y/kJAhjuRGRhb6/fjxf+delJZ4M7\nNMUbv+lmYkWhg3vLEFVGEB9wHM7OXSiBY9IyQ7BnTx3IYK8EjtyJfBXkBxyHq5S/rkLO0TPu47G/\naI1JgwPwZCSbs9Q6dyJLczicge6pVauQ3ojKKv575jy6TPvc0LY3bTAiIzjBUFZIrnMnsrQgP+A4\nnHgub7w3qQX+ck9nk6qxB4Y7ka9iY72P3MNkI6pA8LZ1wP4ZQ7j9iB8w3Il8FeQHHNud52g9dUg7\nPHzr9SZVYz8MdyJfBfkBx3a18fvjGJm+0dDGrQP8j+FOVBlBfMCxHXmO1v9xfzcMbN/UpGrsjeFO\nRAH3YVY+Jnyw1dDG0XpgMdyJKKA8R+tL/5CMTi0amFRN+GC4E1FAvPLv7/Dayn2GNo7Wg4fhTkR+\nVVqquP4Z40Zf6yf1Q/MGdUyqKDwx3InIbx5ekInPs4+4j+tERmDXtEEmVhS+GO5EVG1FxSVo++wK\nQ9v2KbchJoqPaDQLw52IqqX3jC9x6OSl5x53j2uIhY/0MrEiAnwIdxGJArAGQG1X/0Wq+rxHHwHw\nKoAhAAoBPKiqmz1fi4js4+jpc7gp7QtD2760wajJjb4swZeR+zkA/VS1QEQiAawTkU9VtewtZoMB\nxLs+egB4w/WZiGzIc3njA71aYeodHUyqhrypMNzVuSdwgesw0vXhuU/wHQAWuPpuFJEGItJMVQ/7\ntVoiMtWeI6dx2+w1hjYub7Qmn+bcRSQCQBaANgBeV9VNHl2aA/ihzHG+q80Q7iIyBsAYAIjlTnpE\nIcVztP7C7e3x294Oc4qhCvkU7qpaAiBRRBoAWCwiHVR1R2VPpqrpANIB58M6KvvzRBR8a/cexf3z\nvja0cbRufZW68qGqJwCsBOC5cPUggJZljlu42ogohDkmLTME+9sP3hScYOezaqutwnAXkSauETtE\npA6AAQB2e3RbCuABceoJ4CTn24lC13tf5102DZM7cyj6tr0m8Ce/+KzaAwcA1UvPqmXAV4ov0zLN\nALzjmnevAWChqn4iImMBQFXnAlgO5zLIfXAuhRwdoHqJKMA8Q335E7cg4br6wSsgNdX4QBTAeZya\nyu2WK8GX1TLbAHTx0j63zNcKYJx/SyMiv8jI8OkBI2nLsvHm2v2GNlPm1vmsWr/gHapEdnZxiuPi\nSPjiFAfgDviSUkVrj42+Nj2TgmvrRwWz0kv4rFq/4K1kRHZ2pSkOAPfP22QI9oZ1ayF35lDzgh1w\n/mURHW1s47NqK40jdyI7K2cqo/DwESR4zK1nTx2I6FoWiAQ+q9YvLPAvSUQB42WKo8vjGfhv9FXu\n41tvaIIFv+se7MqujM+qrTaGO5GdpaW559x/rNcIPce9Y/h2zvQhiKghJhVHgcRwJwoUH1epBJTr\nfI7txmeWPnLr9Xh6SLvg1kJBxXAnCgQfVqkEw8bvj2OkR7Bz64DwIM4l6sGXlJSkmZmZppybKOAc\nDu/L+Vq1AnJzg1OCxwXTcX1bY+LAtkE5NwWOiGSpalJF/ThyJwoEE2/Eef/rPEz6aLuhjaP18MNw\nJwoEk27E8RytvzoyEXckNg/oOcmaeBNTuOAue8EV5Btxpizd6XWjLwZ7+OLIPRxY5OJeWAnSjTiq\nirinjVsHfPRYb3SNvdqv56HQwwuq4cACF/fI/+6asx7f5p0wtHFu3f54QZUu4S57tlJcUor41E8N\nbRsm9cN1DeqYVBFZEcM9HHCXPdvwnFcHOFon73hBNRxwl72Qd/T0ucuCfecLAxnsVC6O3MMBd9kL\naRytU1Uw3MMFd9kLOTsOnsSw/1lnaONGX+QrhjuRBXmO1q9vUhdfTehjTjEUkhjuRBaydOshPPHe\nt4Y2TsFQVTDciSzCc7R+X/eWmDG8k0nVUKhjuBOZ7KUVu/HGqhxDG0frVF0MdyITeY7W0+7qgFE9\nWplUDdkJ17mT/Vlw07R75/7H60ZfDHbyF47cyd4stmmat42+Fj7SC93jGga9FrI3bhxG9mahTdN4\nMxL5AzcOIwIssWlaUXEJ2j67wtC27s990eLq6HJ+gqj6GO5kbyZvmsbROpmFF1TJ3kzaNO3wybOX\nBXv21Gpu9GXBC8NkXRy5k72ZsGlaQEbrFrswTNZX4QVVEWkJYAGAawEogHRVfdWjTx8ASwDsdzV9\npKpTr/S6vKBKdrNu7zH8Zt4mQ9v+GUMg4oeNvix0YZjM5c8LqhcATFDVzSISAyBLRD5X1WyPfmtV\ndVhViiUKdZ6j9Q7N6+OTx2/x3wkscGGYQkuF4a6qhwEcdn19WkR2AWgOwDPcicJO+pocTF++29AW\nkAumfJoWVVKlLqiKiANAFwCbvHy7t4hsE5FPRaS9H2ojsjTHpGWGYB/asVngVsLwaVpUST5fUBWR\negA+BPBHVT3l8e3NAGJVtUBEhgD4GEC8l9cYA2AMAMRyxEEh6qF3MvHFriOGtoAvb+TTtKiSfLpD\nVUQiAXwC4N+qOsuH/rkAklT1WHl9eEGVQpHn3PpzwxLwu5vjTKqGwpHfLqiK81L/PAC7ygt2EWkK\n4Iiqqoh0h3O653glayayrPjU5SguMQ6EeDMSWZkvc+7JAO4H0E9Etrg+hojIWBEZ6+pzD4AdIrIV\nwN8BjFSzNq0he7DIDTulpQrHpGWGYP/fh3sw2MnyfFktsw7AFRfqquprAF7zV1EU5ixyww63DqBQ\nxl0hyXpMvmHnVFExOk35zNDGjb7IKrgrJIUuE2/Y4Wid7ILhTtZjwg07+34qQP9Zqw1tu6YOQp1a\nEQE7J1EgMdzJetLSjHPuQEBv2OFoneyI4U7WE6Qbdr7IPoKHFhiv+/htoy8ikzHcyZpGjQrqtrzN\nrorCf55OCdj5iIKN4U5hZfbne/Dql3sNbZyCITtiuFPY8Byt35vUAn+5p7NJ1RAFFsOdbO/JD7Zi\nUVa+oY2jdbI7hjvZmudofcbwjrivO3ckJftjuJMt3fqXlcj7udDQxtE6hROGO9lKSami9TPLDW3L\nn7gFCdfVN6kiInMw3Mk2eDMS0SUMdwp5J88Wo/MLxo2+sib3R6N6tU2qiMh8DHcKaRytE3nHcKeQ\nlHO0ACl/NW70tefFwahVs1LPfCeyLYY7hRzP0Xq92jWx44WBJlVDZE0MdwoZq777CQ++/Y2hjVMw\nRN4x3CkkeI7Wb0u4FukPVPgwGqKwxXAnS/vH6hzM+HS3oY2jdaKKMdzJsjxH6xMH3ohxfduYVA1R\naGG4k+XM+HQX/rH6e0MbR+tElcNwJ0vxHK0vfKQXusc1NKkaotDFcCdL+PWbG7Eh57ihjaN1oqpj\nuJOpLpSUok3qp4a2tTeeQsvR95lUEZE9MNzJNG2eWY4LpWpoy31pGBAdDdQqDegzVInsjuFOQedt\no6/ts0cg5vxZ50FhIZCaynAnqgaGOwXVZVsHnCvEjr/de3nHvLwgVURkTwx3CoofTxah54wvDW05\n04cg4vo47z8Qy0fhEVUHw50CznO03ufGJpg/urvzIC0NGDPGORVzUXS0s52IqqzC/VFFpKWIrBSR\nbBHZKSLjvfQREfm7iOwTkW0i0jUw5VIo2Xno5GXBnjtz6KVgB5zz6unpQKtWgIjzc3o659uJqsmX\nkfsFABNUdbOIxADIEpHPVTW7TJ/BAOJdHz0AvOH6TGHKM9RfursjfnVTOVMto0YxzIn8rMJwV9XD\nAA67vj4tIrsANAdQNtzvALBAVRXARhFpICLNXD9LYeTLXUfw+3cyDW28GYko+Co15y4iDgBdAGzy\n+FZzAD+UOc53tTHcw4jnaD3joR5IbtPYpGqIwpvP4S4i9QB8COCPqnqqKicTkTEAxgBALFdD2Mbb\n6/fjhX9lG9o4Wicyl0/hLiKRcAZ7hqp+5KXLQQAtyxy3cLUZqGo6gHQASEpKUs/vU2hRVcQ9vdzQ\n9sWfbkWba2JMqoiILqow3EVEAMwDsEtVZ5XTbSmAP4jI+3BeSD3J+XZ7m/zxdry70XijEUfrRNbh\ny8g9GcD9ALaLyBZX2zMAYgFAVecCWA5gCIB9AAoBjPZ/qWQF3jb6ypzcH43r1TapIiLyxpfVMusA\nSAV9FMA4fxVF1nT3GxuQdeC/7uOWDetg7VP9TKyIiMrDO1SpQqeLitFxinGjr93TBiEqMsKkioio\nIgx3uqL41OUoLrl07Xtwh6Z44zfdTKyIiHzBcCev8v9biJtfWmlo+376ENSoccUZOiKyCIY7Xcbz\nZqQnUuLxpwE3mFQNEVUFw53ctv5wAne8vt7QxuWNRKGJ4U4ALh+t/+1XibizS3OTqiGi6mK4h7kV\nOw5j7LubDW0crROFPoZ7GPMcrS98pBe6xzU0qRoi8ieGexiauzoHMz/dbWjjaJ3IXhjuYcTbRl8r\nn+yDuMZ1TaqIiAKF4R4mJizcig835xvaOFonsi+Gu82dv1CKGyYbN/ra8twANIiuZVJFRBQMDHcb\nG/zqWuw6fOm5Km2bxmDFH281sSIiChaGuw2dLCxG56nGjb6+e3EQatfkRl9E4YLhbjOeyxvv6tIc\ns3+VaFI1RGSWGmYXYCsZGYDDAdSo4fyckRG0U/90uuiyYN8/YwiDnShMMdz9JSMDGDMGOHAAUHV+\nHjMmKAGf8tdV6J72pfv4qUE3InfmUDifkEhBZeIveKKyxPkQpeBLSkrSzMxMU84dEA6HM9A9tWoF\n5OYG5JT7fipA/1mrDW1c3miii7/gCwsvtUVHA+npwKhR5tVFtiIiWaqaVGE/hruf1KjhHLF7EgFK\nS/1+Os8pmA8f7Y1ura72+3moEkz4BU/hx9dw57SMv8TGVq69ir7J/dkQ7CLO0brlgz0cpivy8irX\nThRAXC3jL2lp3v8kT0vz2yk8R+shs3WA53TFxesRgL2mK2JjvY/c/fwLnsgXHLn7y6hRzrnVVq2c\nw+lWrfw217ps22FDsLdtGoPcmUNDI9gBIDXV+EsPcB6npppTT6CkpTl/oZfl51/wRL7inLuFedvo\nK3NyfzSuV9ukiqooyNcjTJWR4fyllZfnHLGnpdnrrxMyna9z7pyWsah/rv0eLy7b5T4e2rEZXh/V\n1cSKqiGcpitGjWKYkyUw3C2muKQU8anGjb6ypw5EdK0Q/qcKwvUIIjLinLuFTFm60xDsj/VpjdyZ\nQ30LdiuvRgng9Qgi8i6Eh4P2cbqoGB2nGDf6ypk+BBE1fLzDNBRWo3C6giioeEHVZL9962us3nPU\nfTz9ro74dY9KzkXz5hmisMELqhb348ki9JzxpaFt/4whVdsPhjfPEJEHhrsJbn7pK+T/96z7eN5v\nk5DS7tqqv2A4rUYhIp9UeEFVRN4SkZ9EZEc53+8jIidFZIvr4zn/l2kPe46chmPSMkOw584cWr1g\nB3jzDBFdxpeR+3wArwFYcIU+a1V1mF8qsinPrQOWjEtG55YN/PPiFy9U8uYZInKpMNxVdY2IOAJf\nij1tyDmGX7+5yX1ct1YEdk4d5P8TcTUKEZXhrzn33iKyDcBBAE+q6k4/vW5I8xytr5nYF7GNosvp\nTUTkP/4I980AYlW1QESGAPgYQLy3jiIyBsAYAIi18cW+JVsOYvz7W9zHnVs2wJJxySZWREThptrh\nrqqnyny9XETmiEhjVT3mpW86gHTAuc69uue2Gm8bfX377ABcXbeWSRURUbiq9vYDItJUXIuzRaS7\n6zWPV/d1Q82SLQcNwT68S3PkzhzKYCciU1Q4cheR9wD0AdBYRPIBPA8gEgBUdS6AewA8KiIXAJwF\nMFLNuu3VBN42+vruxUGoXTPCpIqIiHxbLXNfBd9/Dc6lkmEnfU0Opi/f7T5++Z5OGJHU0sSKiIic\neIdqFZw5dwHtn/+3oe376UNQw9eNvoiIAozhXkmLsvLx5Adb3cdvj74JfW+8xsSKiIgux3D30ami\nYnQqsy1vncgI7JoWgJuRiIj8gOHuA8+59VVP9oEjVB5OTURhieF+BT+dLkL3tEvb8v7+5jg8OyzB\nxIqIiHzDcC9H2rJsvLl2v/v462dScE39KBMrIiLyHcPdw4HjZ/CLl1e5j/88qC0e7dPavIKIiKqA\n4V7G+Pe/xZIth9zHW5+/DVfViTSxIiKiqqn29gN2sPPQSTgmLXMH+1/u6YTcmUO9B3tGhvOZpTVq\nOD9nZAS1ViIiX4T1yF1VMTJ9Izbt/xkAEBNVE9+k9kdUZDlbB2RkAGPGAIWFzuMDB5zHAPdSJyJL\nEbO2gUlKStLMzExTzg0AG78/jpHpG93Hbz6QhAEJFTzuzuHw/qzSVq2A3Fy/1kdE5I2IZKlqUkX9\nwm7kfqGkFANmr8H+Y2cAAG2uqYcV429BzQgfZqjy8irXTkRkkrAK9xU7fsTYd7Pcxwsf6YXucQ19\nf4HYWO8jdxs/eISIQlNYhHtRcQm6TvschedLAADJbRrh3d/3gGsbet+lpRnn3AEgOtrZTkRkIaG1\nWqYKK1X+3zd5aPvsCnewfzr+FmQ81LPywQ44L5qmpzvn2EWcn9PTeTGViCwndEbulVypcrKwGJ2n\nXtroa3jX5ph1b2L16xg1imFORJYXOqtlKrFS5fWV+/Dyv79zH699qi9aNoyuWqFERBZiv9UyPqxU\nOXKqCD1EpYQYAAAEFElEQVSmX9roa+wvWmPS4LaBroyIyHJCJ9wrWKkyZelOzN+Q627+JrU/msTU\nDlJxRETWEjrhXs5Klf3PzUDfScvcTZOHtsNDt1xvQoFERNYROuF+8SJmaiqQlweNjcUfHpmNZXtq\nubtsn3IbYqK40RcRUeiEO+BeqbI9/yR++do64KSzeda9nTG8awtzayMispDQCncAP/xc6Ax2AI3q\n1sL6Sf3K3+iLiChMhVy416tdE8ltGuH3N8ehX9sKNvoiIgpTIRfuV9ethYyHeppdBhGRpYXW9gNE\nROQThjsRkQ0x3ImIbIjhTkRkQwx3IiIbYrgTEdkQw52IyIYY7kRENmTawzpE5CgAL3v4XqYxgGMB\nLicU8X0pH98b7/i+lC+U3ptWqtqkok6mhbuvRCTTl6eOhBu+L+Xje+Md35fy2fG94bQMEZENMdyJ\niGwoFMI93ewCLIrvS/n43njH96V8tntvLD/nTkRElRcKI3ciIqokS4a7iLQUkZUiki0iO0VkvNk1\nWYmIRIjItyLyidm1WImINBCRRSKyW0R2iUgvs2uyChH5P67/SztE5D0RiTK7JrOIyFsi8pOI7CjT\n1lBEPheRva7PV5tZoz9YMtwBXAAwQVUTAPQEME5EEkyuyUrGA9hldhEW9CqAFaraFkBn8D0CAIhI\ncwBPAEhS1Q4AIgCMNLcqU80HMMijbRKAL1U1HsCXruOQZslwV9XDqrrZ9fVpOP+TNje3KmsQkRYA\nhgL4p9m1WImIXAXgVgDzAEBVz6vqCXOrspSaAOqISE0A0QAOmVyPaVR1DYCfPZrvAPCO6+t3ANwZ\n1KICwJLhXpaIOAB0AbDJ3Eos428AngJQanYhFhMH4CiAt11TVv8UkbpmF2UFqnoQwCsA8gAcBnBS\nVT8ztyrLuVZVD7u+/hFAyD+g2dLhLiL1AHwI4I+qesrseswmIsMA/KSqWWbXYkE1AXQF8IaqdgFw\nBjb409ofXPPHd8D5C/A6AHVF5DfmVmVd6lxCGPLLCC0b7iISCWewZ6jqR2bXYxHJAG4XkVwA7wPo\nJyLvmluSZeQDyFfVi3/hLYIz7AnoD2C/qh5V1WIAHwHobXJNVnNERJoBgOvzTybXU22WDHcRETjn\nTnep6iyz67EKVX1aVVuoqgPOC2JfqSpHYABU9UcAP4jIja6mFADZJpZkJXkAeopItOv/Vgp4sdnT\nUgC/dX39WwBLTKzFLywZ7nCOUO+Hc2S6xfUxxOyiyPIeB5AhItsAJAKYbnI9luD6a2YRgM0AtsP5\n/952d2T6SkTeA/AfADeKSL6I/B7ATAADRGQvnH/pzDSzRn/gHapERDZk1ZE7ERFVA8OdiMiGGO5E\nRDbEcCcisiGGOxGRDTHciYhsiOFORGRDDHciIhv6/1anuPjU+lrZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14faa518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing... (Mean square loss Comparison)\n",
      "Testing cost= 0.0757322\n",
      "Absolute mean square loss difference: 0.00633085\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1600e8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "\n",
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "\n",
    "# Training Data\n",
    "train_X = numpy.asarray([3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n",
    "                         7.042,10.791,5.313,7.997,5.654,9.27,3.1])\n",
    "train_Y = numpy.asarray([1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n",
    "                         2.827,3.465,1.65,2.904,2.42,2.94,1.3])\n",
    "n_samples = train_X.shape[0]\n",
    "\n",
    "# tf Graph Input\n",
    "X = tf.placeholder(\"float\")\n",
    "Y = tf.placeholder(\"float\")\n",
    "\n",
    "# Set model weights\n",
    "W = tf.Variable(rng.randn(), name=\"weight\")\n",
    "b = tf.Variable(rng.randn(), name=\"bias\")\n",
    "\n",
    "# Construct a linear model\n",
    "pred = tf.add(tf.multiply(X, W), b)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)\n",
    "# Gradient descent\n",
    "#  Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "    c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "    print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "        \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "    # Fit all training data\n",
    "    for epoch in range(training_epochs):\n",
    "#         for (x, y) in zip(train_X, train_Y):\n",
    "#             sess.run(optimizer, feed_dict={X: x, Y: y})\n",
    "        sess.run(optimizer, feed_dict={X: train_X, Y: train_Y})\n",
    "\n",
    "        # Display logs per epoch step\n",
    "        if (epoch+1) % display_step == 0:\n",
    "            c = sess.run(cost, feed_dict={X: train_X, Y:train_Y})\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c), \\\n",
    "                \"W=\", sess.run(W), \"b=\", sess.run(b))\n",
    "\n",
    "    print(\"Optimization Finished!\")\n",
    "    training_cost = sess.run(cost, feed_dict={X: train_X, Y: train_Y})\n",
    "    print(\"Training cost=\", training_cost, \"W=\", sess.run(W), \"b=\", sess.run(b), '\\n')\n",
    "\n",
    "    # Graphic display\n",
    "    plt.plot(train_X, train_Y, 'ro', label='Original data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Testing example, as requested (Issue #2)\n",
    "    test_X = numpy.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\n",
    "    test_Y = numpy.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n",
    "\n",
    "    print(\"Testing... (Mean square loss Comparison)\")\n",
    "    testing_cost = sess.run(\n",
    "        tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * test_X.shape[0]),\n",
    "        feed_dict={X: test_X, Y: test_Y})  # same function as cost above\n",
    "    print(\"Testing cost=\", testing_cost)\n",
    "    print(\"Absolute mean square loss difference:\", abs(\n",
    "        training_cost - testing_cost))\n",
    "\n",
    "    plt.plot(test_X, test_Y, 'bo', label='Testing data')\n",
    "    plt.plot(train_X, sess.run(W) * train_X + sess.run(b), label='Fitted line')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:175: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Ran 49times\n",
      "W=[[-0.41234806]\n",
      " [ 0.84875554]\n",
      " [ 0.72421205]\n",
      " [-0.13422124]\n",
      " [-0.22062373]\n",
      " [ 0.89979678]\n",
      " [-1.05786848]\n",
      " [ 0.10187266]\n",
      " [-0.65967542]\n",
      " [-1.63823366]\n",
      " [-0.40075183]\n",
      " [ 0.15633889]\n",
      " [-1.97006929]]\n",
      "b=[ 8.53464222]\n",
      "Ran 99times\n",
      "W=[[-0.41290101]\n",
      " [ 0.79609215]\n",
      " [ 0.6384666 ]\n",
      " [ 0.3982082 ]\n",
      " [-0.10962778]\n",
      " [ 2.01994848]\n",
      " [-0.74820113]\n",
      " [-0.54829645]\n",
      " [-0.243276  ]\n",
      " [-1.4715097 ]\n",
      " [-0.95805013]\n",
      " [ 0.35740408]\n",
      " [-2.65664744]]\n",
      "b=[ 14.04894829]\n",
      "Ran 149times\n",
      "W=[[-0.41177493]\n",
      " [ 0.763017  ]\n",
      " [ 0.54649603]\n",
      " [ 0.63333941]\n",
      " [-0.1290236 ]\n",
      " [ 2.61214805]\n",
      " [-0.57119387]\n",
      " [-0.97016823]\n",
      " [ 0.07765383]\n",
      " [-1.34974039]\n",
      " [-1.24583387]\n",
      " [ 0.50610209]\n",
      " [-3.05040288]]\n",
      "b=[ 17.39001465]\n",
      "Ran 199times\n",
      "W=[[-0.42063722]\n",
      " [ 0.7449193 ]\n",
      " [ 0.45478287]\n",
      " [ 0.72926003]\n",
      " [-0.21221751]\n",
      " [ 2.91858697]\n",
      " [-0.4662112 ]\n",
      " [-1.26163721]\n",
      " [ 0.32524499]\n",
      " [-1.26844418]\n",
      " [-1.40478086]\n",
      " [ 0.61772925]\n",
      " [-3.28319359]]\n",
      "b=[ 19.41457176]\n",
      "Ran 249times\n",
      "W=[[-0.43807551]\n",
      " [ 0.73640352]\n",
      " [ 0.37000704]\n",
      " [ 0.76226515]\n",
      " [-0.32158816]\n",
      " [ 3.06842446]\n",
      " [-0.39879104]\n",
      " [-1.47833776]\n",
      " [ 0.52170354]\n",
      " [-1.21586633]\n",
      " [-1.500898  ]\n",
      " [ 0.70016402]\n",
      " [-3.42366052]]\n",
      "b=[ 20.64119148]\n",
      "Ran 299times\n",
      "W=[[-0.46120811]\n",
      " [ 0.73449731]\n",
      " [ 0.2945933 ]\n",
      " [ 0.76845694]\n",
      " [-0.43864754]\n",
      " [ 3.1325233 ]\n",
      " [-0.35151288]\n",
      " [-1.64989877]\n",
      " [ 0.68236613]\n",
      " [-1.18315709]\n",
      " [-1.56599259]\n",
      " [ 0.75992972]\n",
      " [-3.5103519 ]]\n",
      "b=[ 21.38450623]\n",
      "Ran 349times\n",
      "W=[[-0.48750076]\n",
      " [ 0.7373513 ]\n",
      " [ 0.22886959]\n",
      " [ 0.76443768]\n",
      " [-0.55461711]\n",
      " [ 3.15000725]\n",
      " [-0.31556934]\n",
      " [-1.79237008]\n",
      " [ 0.81746435]\n",
      " [-1.16416955]\n",
      " [-1.61529469]\n",
      " [ 0.80246168]\n",
      " [-3.56525946]]\n",
      "b=[ 21.83498955]\n",
      "Ran 399times\n",
      "W=[[-0.51508868]\n",
      " [ 0.74365699]\n",
      " [ 0.17229216]\n",
      " [ 0.75750983]\n",
      " [-0.66554248]\n",
      " [ 3.1426301 ]\n",
      " [-0.28642583]\n",
      " [-1.91473413]\n",
      " [ 0.93378508]\n",
      " [-1.15475297]\n",
      " [-1.65596879]\n",
      " [ 0.83214366]\n",
      " [-3.60109901]]\n",
      "b=[ 22.10778236]\n",
      "Ran 449times\n",
      "W=[[-0.54269791]\n",
      " [ 0.75241464]\n",
      " [ 0.12399037]\n",
      " [ 0.75060946]\n",
      " [-0.76982039]\n",
      " [ 3.12251782]\n",
      " [-0.26168561]\n",
      " [-2.02221322]\n",
      " [ 1.03588498]\n",
      " [-1.15213418]\n",
      " [-1.69133413]\n",
      " [ 0.85240853]\n",
      " [-3.6253221 ]]\n",
      "b=[ 22.2730484]\n",
      "Ran 499times\n",
      "W=[[-0.56955564]\n",
      " [ 0.76285303]\n",
      " [ 0.08301955]\n",
      " [ 0.74473214]\n",
      " [-0.86698532]\n",
      " [ 3.09643722]\n",
      " [-0.24003871]\n",
      " [-2.11801291]\n",
      " [ 1.12685061]\n",
      " [-1.15440965]\n",
      " [-1.72296834]\n",
      " [ 0.86586285]\n",
      " [-3.64232802]]\n",
      "b=[ 22.37337494]\n",
      "Done!\n",
      "\n",
      "Running test...\n",
      "\n",
      "loss =0.00154577\n",
      "Real value Y: 19.7\n",
      "Pred Y: [[ 20.94949341]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "\n",
    "boston = load_boston()\n",
    "\n",
    "data = boston.data\n",
    "label = boston.target\n",
    "\n",
    "# normalized data\n",
    "data -= np.mean(data, axis=0)\n",
    "data /= np.std(data, axis=0)\n",
    "\n",
    "M = boston.data.shape[0]\n",
    "\n",
    "\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "X = tf.placeholder(tf.float32, [1, 13], name='X')\n",
    "\n",
    "W = tf.Variable(tf.random_normal([13, 1]), name='weights')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.add(tf.matmul(X, W), b)\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(hypothesis - Y)) / (2. * (M - 1))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "\n",
    "train_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    for i in range(0, 500):\n",
    "        for l in range(M):\n",
    "            _, loss_val, hypo = sess.run(\n",
    "                [train_op, loss, hypothesis],\n",
    "                feed_dict={X: data[l, :].reshape([1, 13]),\n",
    "                           Y: label[l]})\n",
    "        if (i + 1) % 50 == 0:\n",
    "            print(\"Ran \" + str(i) + \"times\\nW=\" + \\\n",
    "                str(sess.run(W)) + \"\\nb=\" + str(sess.run(b)))\n",
    "\n",
    "    print(\"Done!\\n\")\n",
    "    print(\"Running test...\\n\")\n",
    "    t = sess.run(\n",
    "        loss, feed_dict={X: data[50].reshape([1, 13]),\n",
    "                         Y: label[50]})\n",
    "    print(\"loss =\" + str(t))\n",
    "    print(\"Real value Y: \" + str(label[50]))\n",
    "    print(\"Pred Y: \" + str(sess.run(hypothesis,\n",
    "                                    feed_dict={X: data[50].reshape([1, 13])})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.5 -1.5 -1.5]\n",
      " [ 1.5  1.5  1.5]]\n",
      "[ 1.5  1.5  1.5]\n",
      "[[-1. -1. -1.]\n",
      " [ 1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "foo=[[1,2,3],[4,5,6]]\n",
    "foo -= np.mean(foo, axis=0)\n",
    "print(foo)\n",
    "\n",
    "print(np.std(foo, axis=0))\n",
    "\n",
    "foo /= np.std(foo, axis=0)\n",
    "print(foo)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
