{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Example code for TensorFlow Wide & Deep Tutorial using TF.Learn API.\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "import tempfile\n",
    "\n",
    "import pandas as pd\n",
    "from six.moves import urllib\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    \"age\", \"workclass\", \"fnlwgt\", \"education\", \"education_num\",\n",
    "    \"marital_status\", \"occupation\", \"relationship\", \"race\", \"gender\",\n",
    "    \"capital_gain\", \"capital_loss\", \"hours_per_week\", \"native_country\",\n",
    "    \"income_bracket\"\n",
    "]\n",
    "\n",
    "gender = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"gender\", [\"Female\", \"Male\"])\n",
    "education = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"education\", [\n",
    "        \"Bachelors\", \"HS-grad\", \"11th\", \"Masters\", \"9th\",\n",
    "        \"Some-college\", \"Assoc-acdm\", \"Assoc-voc\", \"7th-8th\",\n",
    "        \"Doctorate\", \"Prof-school\", \"5th-6th\", \"10th\", \"1st-4th\",\n",
    "        \"Preschool\", \"12th\"\n",
    "    ])\n",
    "marital_status = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"marital_status\", [\n",
    "        \"Married-civ-spouse\", \"Divorced\", \"Married-spouse-absent\",\n",
    "        \"Never-married\", \"Separated\", \"Married-AF-spouse\", \"Widowed\"\n",
    "    ])\n",
    "relationship = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"relationship\", [\n",
    "        \"Husband\", \"Not-in-family\", \"Wife\", \"Own-child\", \"Unmarried\",\n",
    "        \"Other-relative\"\n",
    "    ])\n",
    "workclass = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"workclass\", [\n",
    "        \"Self-emp-not-inc\", \"Private\", \"State-gov\", \"Federal-gov\",\n",
    "        \"Local-gov\", \"?\", \"Self-emp-inc\", \"Without-pay\", \"Never-worked\"\n",
    "    ])\n",
    "\n",
    "# To show an example of hashing:\n",
    "occupation = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"occupation\", hash_bucket_size=1000)\n",
    "native_country = tf.feature_column.categorical_column_with_hash_bucket(\n",
    "    \"native_country\", hash_bucket_size=1000)\n",
    "\n",
    "# Continuous base columns.\n",
    "age = tf.feature_column.numeric_column(\"age\")\n",
    "education_num = tf.feature_column.numeric_column(\"education_num\")\n",
    "capital_gain = tf.feature_column.numeric_column(\"capital_gain\")\n",
    "capital_loss = tf.feature_column.numeric_column(\"capital_loss\")\n",
    "hours_per_week = tf.feature_column.numeric_column(\"hours_per_week\")\n",
    "\n",
    "# Transformations.\n",
    "age_buckets = tf.feature_column.bucketized_column(\n",
    "    age, boundaries=[18, 25, 30, 35, 40, 45, 50, 55, 60, 65])\n",
    "\n",
    "# Wide columns and deep columns.\n",
    "base_columns = [\n",
    "    gender, education, marital_status, relationship, workclass, occupation,\n",
    "    native_country, age_buckets,\n",
    "]\n",
    "\n",
    "crossed_columns = [\n",
    "    tf.feature_column.crossed_column(\n",
    "        [\"education\", \"occupation\"], hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(\n",
    "        [age_buckets, \"education\", \"occupation\"], hash_bucket_size=1000),\n",
    "    tf.feature_column.crossed_column(\n",
    "        [\"native_country\", \"occupation\"], hash_bucket_size=1000)\n",
    "]\n",
    "\n",
    "deep_columns = [\n",
    "    tf.feature_column.indicator_column(workclass),\n",
    "    tf.feature_column.indicator_column(education),\n",
    "    tf.feature_column.indicator_column(gender),\n",
    "    tf.feature_column.indicator_column(relationship),\n",
    "    # To show an example of embedding\n",
    "    tf.feature_column.embedding_column(native_country, dimension=8),\n",
    "    tf.feature_column.embedding_column(occupation, dimension=8),\n",
    "    age,\n",
    "    education_num,\n",
    "    capital_gain,\n",
    "    capital_loss,\n",
    "    hours_per_week,\n",
    "]\n",
    "\n",
    "\n",
    "def build_estimator(model_dir, model_type):\n",
    "  \"\"\"Build an estimator.\"\"\"\n",
    "  if model_type == \"wide\":\n",
    "    m = tf.estimator.LinearClassifier(\n",
    "        model_dir=model_dir, feature_columns=base_columns + crossed_columns)\n",
    "  elif model_type == \"deep\":\n",
    "    m = tf.estimator.DNNClassifier(\n",
    "        model_dir=model_dir,\n",
    "        feature_columns=deep_columns,\n",
    "        hidden_units=[100, 50])\n",
    "  else:\n",
    "    m = tf.estimator.DNNLinearCombinedClassifier(\n",
    "        model_dir=model_dir,\n",
    "        linear_feature_columns=crossed_columns,\n",
    "        dnn_feature_columns=deep_columns,\n",
    "        dnn_hidden_units=[100, 50])\n",
    "  return m\n",
    "\n",
    "\n",
    "def input_fn(data_file, num_epochs, shuffle):\n",
    "  \"\"\"Input builder function.\"\"\"\n",
    "  df_data = pd.read_csv(\n",
    "      tf.gfile.Open(data_file),\n",
    "      names=CSV_COLUMNS,\n",
    "      skipinitialspace=True,\n",
    "      engine=\"python\",\n",
    "      skiprows=1)\n",
    "  # remove NaN elements\n",
    "  df_data = df_data.dropna(how=\"any\", axis=0)\n",
    "  labels = df_data[\"income_bracket\"].apply(lambda x: \">50K\" in x).astype(int)\n",
    "  return tf.estimator.inputs.pandas_input_fn(\n",
    "      x=df_data,\n",
    "      y=labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=num_epochs,\n",
    "      shuffle=shuffle,\n",
    "      num_threads=5)\n",
    "\n",
    "\n",
    "def train_and_eval(model_dir, model_type, train_steps, train_data, test_data):\n",
    "  \"\"\"Train and evaluate the model.\"\"\"\n",
    "  train_file_name, test_file_name = 'adult_train.csv','adult_test.csv'\n",
    "  model_dir = tempfile.mkdtemp() if not model_dir else model_dir\n",
    "\n",
    "  m = build_estimator(model_dir, model_type)\n",
    "  # set num_epochs to None to get infinite stream of data.\n",
    "  m.train(\n",
    "      input_fn=input_fn(train_file_name, num_epochs=None, shuffle=True),\n",
    "      steps=train_steps)\n",
    "  # set steps to None to run evaluation until all data consumed.\n",
    "  results = m.evaluate(\n",
    "      input_fn=input_fn(test_file_name, num_epochs=1, shuffle=False),\n",
    "      steps=None)\n",
    "  print(\"model directory = %s\" % model_dir)\n",
    "  for key in sorted(results):\n",
    "    print(\"%s: %s\" % (key, results[key]))\n",
    "\n",
    "\n",
    "FLAGS = None\n",
    "\n",
    "\n",
    "def main(_):\n",
    "  train_and_eval(FLAGS.model_dir, FLAGS.model_type, FLAGS.train_steps,\n",
    "                 FLAGS.train_data, FLAGS.test_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  parser = argparse.ArgumentParser()\n",
    "  parser.register(\"type\", \"bool\", lambda v: v.lower() == \"true\")\n",
    "  parser.add_argument(\n",
    "      \"--model_dir\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Base directory for output models.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--model_type\",\n",
    "      type=str,\n",
    "      default=\"wide_n_deep\",\n",
    "      help=\"Valid model types: {'wide', 'deep', 'wide_n_deep'}.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--train_steps\",\n",
    "      type=int,\n",
    "      default=2000,\n",
    "      help=\"Number of training steps.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--train_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the training data.\"\n",
    "  )\n",
    "  parser.add_argument(\n",
    "      \"--test_data\",\n",
    "      type=str,\n",
    "      default=\"\",\n",
    "      help=\"Path to the test data.\"\n",
    "  )\n",
    "  FLAGS, unparsed = parser.parse_known_args()\n",
    "  tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
